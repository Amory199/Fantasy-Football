{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023356c1",
   "metadata": {},
   "source": [
    "# FantasyTrivia: Graph-RAG for Fantasy Premier League\n",
    "\n",
    "## Retrieval-Augmented Generation Using Neo4j Knowledge Graph\n",
    "\n",
    "This notebook demonstrates how to build a Graph-RAG system for answering questions about Fantasy Premier League 2022-23 season.\n",
    "\n",
    "**What we'll cover:**\n",
    "1. Connect to Neo4j knowledge graph\n",
    "2. Create player embeddings (numerical + text)\n",
    "3. Build FAISS retriever\n",
    "4. Compare retrieval methods\n",
    "5. Implement RAG with LangChain\n",
    "6. Answer FPL questions with grounded responses\n",
    "\n",
    "**Dataset:** 51,952 player performances across 2 seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a42380",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa02946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install neo4j sentence-transformers faiss-cpu langchain langchain-community pandas plotly -q\n",
    "\n",
    "print(\"✓ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from neo4j import GraphDatabase\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d1453",
   "metadata": {},
   "source": [
    "## 2. Connect to Neo4j Knowledge Graph\n",
    "\n",
    "Our knowledge graph contains:\n",
    "- **1,513 Players**\n",
    "- **42 Teams**  \n",
    "- **760 Fixtures**\n",
    "- **51,952 Performance records** (PLAYED_IN relationships)\n",
    "\n",
    "Each performance has 19 properties including goals, assists, minutes, fantasy points, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cf381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Neo4j configuration\n",
    "def load_config():\n",
    "    config = {}\n",
    "    with open('../config.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                config[key] = value\n",
    "    return config\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\n",
    "    config['URI'],\n",
    "    auth=(config['USERNAME'], config['PASSWORD'])\n",
    ")\n",
    "\n",
    "print(f\"✓ Connected to Neo4j at {config['URI']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d03ea",
   "metadata": {},
   "source": [
    "## 3. Verify Connection & Explore Graph Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ff3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get database statistics\n",
    "with driver.session() as session:\n",
    "    # Count nodes by label\n",
    "    stats = session.run(\"\"\"\n",
    "        MATCH (p:Player) WITH count(p) as players\n",
    "        MATCH (t:Team) WITH players, count(t) as teams\n",
    "        MATCH (f:Fixture) WITH players, teams, count(f) as fixtures\n",
    "        MATCH ()-[r:PLAYED_IN]->() \n",
    "        RETURN players, teams, fixtures, count(r) as performances\n",
    "    \"\"\").single()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"KNOWLEDGE GRAPH STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Players:       {stats['players']:,}\")\n",
    "    print(f\"Teams:         {stats['teams']:,}\")\n",
    "    print(f\"Fixtures:      {stats['fixtures']:,}\")\n",
    "    print(f\"Performances:  {stats['performances']:,}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5111f",
   "metadata": {},
   "source": [
    "## 4. Fetch Player Data for Embeddings\n",
    "\n",
    "We'll aggregate player statistics for the 2022-23 season to create embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate player stats for 2022-23 season\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (p:Player)-[r:PLAYED_IN]->(f:Fixture {season: '2022-23'})\n",
    "        WITH p,\n",
    "             sum(r.total_points) as total_points,\n",
    "             sum(r.goals_scored) as total_goals,\n",
    "             sum(r.assists) as total_assists,\n",
    "             sum(r.minutes) as total_minutes,\n",
    "             sum(r.clean_sheets) as clean_sheets,\n",
    "             sum(r.saves) as saves,\n",
    "             sum(r.bonus) as bonus,\n",
    "             count(r) as matches_played\n",
    "        WHERE total_minutes > 0\n",
    "        RETURN p.player_name as player,\n",
    "               total_points, total_goals, total_assists,\n",
    "               total_minutes, clean_sheets, saves, bonus,\n",
    "               matches_played\n",
    "        ORDER BY total_points DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    player_stats = [dict(record) for record in result]\n",
    "\n",
    "print(f\"✓ Retrieved stats for {len(player_stats)} players\")\n",
    "print(\"\\nSample (Top 3 Players):\")\n",
    "df_sample = pd.DataFrame(player_stats[:3])\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f41fe",
   "metadata": {},
   "source": [
    "## 5. Create Text Embeddings Using Sentence Transformer\n",
    "\n",
    "We'll use the `all-MiniLM-L6-v2` model - a fast, high-quality sentence embedding model perfect for semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1151d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model\n",
    "print(\"Loading SentenceTransformer model...\")\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device='cpu')\n",
    "print(\"✓ Model loaded!\")\n",
    "\n",
    "# Create text descriptions for each player\n",
    "descriptions = []\n",
    "for player in player_stats:\n",
    "    desc = f\"\"\"\n",
    "    Player {player['player']} played {player['matches_played']} matches\n",
    "    and scored {player['total_points']} fantasy points.\n",
    "    They scored {player['total_goals']} goals and provided {player['total_assists']} assists.\n",
    "    Total minutes played: {player['total_minutes']}.\n",
    "    Clean sheets: {player['clean_sheets']}, Bonus points: {player['bonus']}.\n",
    "    \"\"\"\n",
    "    descriptions.append(desc.strip())\n",
    "\n",
    "print(f\"\\n✓ Created {len(descriptions)} text descriptions\")\n",
    "print(f\"\\nSample description:\\n{descriptions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all descriptions into embeddings\n",
    "print(\"Encoding player descriptions... (this may take 10-20 seconds)\")\n",
    "embeddings = embedder.encode(descriptions, convert_to_numpy=True)\n",
    "\n",
    "print(f\"✓ Created embeddings with shape: {embeddings.shape}\")\n",
    "print(f\"  - {embeddings.shape[0]} players\")\n",
    "print(f\"  - {embeddings.shape[1]} dimensions per embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669977c",
   "metadata": {},
   "source": [
    "## 6. Build FAISS Index for Fast Similarity Search\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) allows us to quickly find the most similar players based on embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16941bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index\n",
    "d = embeddings.shape[1]  # dimension\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance (Euclidean)\n",
    "index.add(embeddings)  # Add all embeddings to the index\n",
    "\n",
    "print(f\"✓ FAISS index built successfully!\")\n",
    "print(f\"  - Index contains {index.ntotal} vectors\")\n",
    "print(f\"  - Each vector has {d} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce79e3",
   "metadata": {},
   "source": [
    "## 7. Test Retrieval - Similarity Search Only\n",
    "\n",
    "Let's test finding similar players using only FAISS similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve similar players\n",
    "def retrieve_similar(query, k=5):\n",
    "    \"\"\"Find k most similar players to the query\"\"\"\n",
    "    # Embed the query\n",
    "    query_emb = embedder.encode([query], convert_to_numpy=True)\n",
    "    \n",
    "    # Search FAISS index\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    \n",
    "    # Get player names\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        results.append({\n",
    "            'rank': i + 1,\n",
    "            'player': player_stats[idx]['player'],\n",
    "            'distance': distances[0][i],\n",
    "            'points': player_stats[idx]['total_points'],\n",
    "            'goals': player_stats[idx]['total_goals']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test query\n",
    "query = \"Who are the best strikers who scored many goals?\"\n",
    "results = retrieve_similar(query, k=5)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Top 5 Similar Players:\")\n",
    "print(\"=\"*70)\n",
    "for r in results:\n",
    "    print(f\"{r['rank']}. {r['player']:<25} | Distance: {r['distance']:.3f} | Goals: {r['goals']:>2} | Points: {r['points']:>3}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b71c5",
   "metadata": {},
   "source": [
    "## 8. Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "Now let's combine retrieval with LLM generation to provide natural language answers grounded in our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d85865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RAG function (mock LLM for demonstration)\n",
    "def rag_answer(query, k=5):\n",
    "    \"\"\"\n",
    "    Retrieval-Augmented Generation:\n",
    "    1. Retrieve relevant players\n",
    "    2. Build context from retrieved data\n",
    "    3. Generate answer using context\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve\n",
    "    retrieved = retrieve_similar(query, k=k)\n",
    "    \n",
    "    # Step 2: Build context\n",
    "    context = f\"Based on FPL 2022-23 season data, here are the top {k} relevant players:\\n\\n\"\n",
    "    for r in retrieved:\n",
    "        player_data = player_stats[player_stats.index(next(p for p in player_stats if p['player'] == r['player']))]\n",
    "        context += f\"- {r['player']}: {player_data['total_points']} points, \"\n",
    "        context += f\"{player_data['total_goals']} goals, {player_data['total_assists']} assists, \"\n",
    "        context += f\"{player_data['matches_played']} matches\\n\"\n",
    "    \n",
    "    # Step 3: Generate answer (mock - in production, would use LLM)\n",
    "    answer = f\"**Query:** {query}\\n\\n\"\n",
    "    answer += f\"**Retrieved Context:**\\n{context}\\n\"\n",
    "    answer += f\"**Answer:** Based on the data, \"\n",
    "    \n",
    "    if \"goal\" in query.lower():\n",
    "        top = retrieved[0]\n",
    "        answer += f\"**{top['player']}** was the top goal scorer with **{top['goals']} goals** and **{top['points']} fantasy points**.\"\n",
    "    elif \"assist\" in query.lower():\n",
    "        player_data = player_stats[player_stats.index(next(p for p in player_stats if p['player'] == retrieved[0]['player']))]\n",
    "        answer += f\"**{retrieved[0]['player']}** had **{player_data['total_assists']} assists** with **{retrieved[0]['points']} fantasy points**.\"\n",
    "    else:\n",
    "        answer += f\"The top performers include **{retrieved[0]['player']}**, **{retrieved[1]['player']}**, and **{retrieved[2]['player']}**.\"\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Test RAG\n",
    "query = \"Who scored the most goals in 2022-23?\"\n",
    "answer = rag_answer(query, k=5)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504659f",
   "metadata": {},
   "source": [
    "## 9. Visualize Top Players\n",
    "\n",
    "Let's visualize some insights from our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Scorers\n",
    "df_top = pd.DataFrame(player_stats[:10])\n",
    "\n",
    "fig = px.bar(df_top, x='total_goals', y='player', orientation='h',\n",
    "             title='Top 10 Goal Scorers - FPL 2022-23',\n",
    "             labels={'total_goals': 'Goals', 'player': 'Player'},\n",
    "             color='total_goals', color_continuous_scale='Reds',\n",
    "             text='total_goals')\n",
    "\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf620965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Goals vs Fantasy Points\n",
    "fig = px.scatter(df_top, x='total_goals', y='total_points', \n",
    "                 text='player', size='matches_played',\n",
    "                 title='Goals vs Fantasy Points (Top 10)',\n",
    "                 labels={'total_goals': 'Goals Scored', 'total_points': 'Fantasy Points'})\n",
    "\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacbe646",
   "metadata": {},
   "source": [
    "## 10. Summary & Key Takeaways\n",
    "\n",
    "### What We Built:\n",
    "1. ✅ **Neo4j Knowledge Graph** with 51,952 performance records\n",
    "2. ✅ **Text Embeddings** using SentenceTransformer (384 dimensions)\n",
    "3. ✅ **FAISS Index** for fast similarity search\n",
    "4. ✅ **Retrieval-Augmented Generation** combining embeddings + context\n",
    "\n",
    "### Advantages of Graph-RAG:\n",
    "- **Structured Data**: Neo4j provides accurate, queryable relationships\n",
    "- **Semantic Search**: Embeddings find contextually similar players\n",
    "- **Grounded Answers**: LLM responses are backed by real data\n",
    "- **No Hallucination**: Answers are limited to what exists in the graph\n",
    "\n",
    "### Next Steps:\n",
    "- Integrate with real LLM (HuggingFace, OpenAI, etc.)\n",
    "- Add more complex Cypher queries for deeper insights\n",
    "- Create Streamlit UI for interactive Q&A\n",
    "- Compare different embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c34d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Neo4j connection\n",
    "driver.close()\n",
    "print(\"✓ Neo4j connection closed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
